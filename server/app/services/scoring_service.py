"""
Scoring Service (Stage 3)

DTW ë™ê¸°í™” ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì—°ê¸°ë¥¼ ë ˆí¼ëŸ°ìŠ¤ ë°°ìš°ì™€ ë¹„êµ í‰ê°€í•©ë‹ˆë‹¤.

í‰ê°€ í•­ëª©:
- Audio: í”¼ì¹˜(ì–µì–‘) + ì—ë„ˆì§€(ë³¼ë¥¨) íŒ¨í„´ ìœ ì‚¬ë„
- Video: ë¸”ë Œë“œì‰ì…(í‘œì •) ìœ ì‚¬ë„

í•µì‹¬ íŠ¹ì§•:
- DTW ì›Œí•‘ ê²½ë¡œë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ í”„ë ˆì„ ëŒ€ í”„ë ˆì„ ë¹„êµ
- ì •ê·œí™”ëœ ë¹„êµë¡œ ê°œì¸ ì°¨ì´(ìŒì—­ëŒ€, ë³¼ë¥¨ ë“±) ë³´ì •
- í•­ëª©ë³„ ì„¸ë¶€ í”¼ë“œë°± ì œê³µ
"""

from __future__ import annotations

from dataclasses import dataclass, field
from enum import Enum
from typing import Optional

import numpy as np
from numpy.typing import NDArray

from app.core.schemas import (
    AnalysisResult,
    DTWResult,
    ScoreDetail,
    ScoringResult,
)


class ScoreGrade(Enum):
    """ì ìˆ˜ ë“±ê¸‰."""
    S = "S"   # 90-100: ì™„ë²½
    A = "A"   # 80-89: ìš°ìˆ˜
    B = "B"   # 70-79: ì–‘í˜¸
    C = "C"   # 60-69: ë³´í†µ
    D = "D"   # 50-59: ë¯¸í¡
    F = "F"   # 0-49: ë…¸ë ¥ í•„ìš”


@dataclass
class FrameScore:
    """í”„ë ˆì„ë³„ ì ìˆ˜ (ë””ë²„ê¹…/ì‹œê°í™”ìš©)."""
    user_frame_idx: int
    actor_frame_idx: int
    timestamp_ms: int
    pitch_score: float = 0.0
    energy_score: float = 0.0
    expression_score: float = 0.0
    combined_score: float = 0.0


@dataclass
class DetailedFeedback:
    """ìƒì„¸ í”¼ë“œë°±."""
    category: str
    score: float
    grade: ScoreGrade
    message: str
    suggestions: list[str] = field(default_factory=list)
    frame_scores: list[float] = field(default_factory=list)  # ì‹œê³„ì—´ ì ìˆ˜


class ScoringService:
    """
    ì—°ê¸° ìŠ¤ì½”ì–´ë§ ì„œë¹„ìŠ¤.
    
    DTW ë™ê¸°í™” ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì™€ ë ˆí¼ëŸ°ìŠ¤ë¥¼ ë¹„êµ í‰ê°€í•©ë‹ˆë‹¤.
    """

    # ê°€ì¤‘ì¹˜ ì„¤ì • (í•©ê³„ = 1.0)
    WEIGHT_PITCH = 0.30      # ì–µì–‘ (ëŒ€ì‚¬ ì „ë‹¬ì— ì¤‘ìš”)
    WEIGHT_ENERGY = 0.20     # ë³¼ë¥¨/ê°•ì„¸
    WEIGHT_EXPRESSION = 0.50  # í‘œì • (ì—°ê¸°ì˜ í•µì‹¬)

    # ë¸”ë Œë“œì‰ì…ë³„ ê°€ì¤‘ì¹˜ (ì—°ê¸°ì—ì„œ ì¤‘ìš”í•œ í‘œì •)
    BLENDSHAPE_WEIGHTS = {
        # ì… ê´€ë ¨ (ëŒ€ì‚¬ ì „ë‹¬)
        "jawOpen": 1.5,
        "mouthSmileLeft": 1.2,
        "mouthSmileRight": 1.2,
        "mouthFrownLeft": 1.2,
        "mouthFrownRight": 1.2,
        "mouthPucker": 1.0,
        "mouthLeft": 0.8,
        "mouthRight": 0.8,
        # ëˆˆì¹ (ê°ì • í‘œí˜„)
        "browInnerUp": 1.3,
        "browDownLeft": 1.2,
        "browDownRight": 1.2,
        "browOuterUpLeft": 1.0,
        "browOuterUpRight": 1.0,
        # ëˆˆ (ê°ì •ì˜ ì°½)
        "eyeWideLeft": 1.3,
        "eyeWideRight": 1.3,
        "eyeSquintLeft": 1.1,
        "eyeSquintRight": 1.1,
        "eyeBlinkLeft": 0.5,   # ëˆˆ ê¹œë¹¡ì„ì€ ë‚®ì€ ê°€ì¤‘ì¹˜
        "eyeBlinkRight": 0.5,
        # ê¸°íƒ€
        "cheekPuff": 0.8,
        "noseSneerLeft": 0.9,
        "noseSneerRight": 0.9,
    }

    def __init__(
        self,
        pitch_weight: float = 0.30,
        energy_weight: float = 0.20,
        expression_weight: float = 0.50,
    ):
        """
        Args:
            pitch_weight: í”¼ì¹˜ ì ìˆ˜ ê°€ì¤‘ì¹˜
            energy_weight: ì—ë„ˆì§€ ì ìˆ˜ ê°€ì¤‘ì¹˜
            expression_weight: í‘œì • ì ìˆ˜ ê°€ì¤‘ì¹˜
        """
        total = pitch_weight + energy_weight + expression_weight
        self.weight_pitch = pitch_weight / total
        self.weight_energy = energy_weight / total
        self.weight_expression = expression_weight / total

        print(f"ğŸ“Š ScoringService: ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ê°€ì¤‘ì¹˜ - í”¼ì¹˜: {self.weight_pitch:.0%}, "
              f"ì—ë„ˆì§€: {self.weight_energy:.0%}, "
              f"í‘œì •: {self.weight_expression:.0%}")

    def score(
        self,
        user_analysis: AnalysisResult,
        reference: AnalysisResult,
        dtw_result: DTWResult,
    ) -> ScoringResult:
        """
        ì‚¬ìš©ì ì—°ê¸° í‰ê°€.
        
        Args:
            user_analysis: ì‚¬ìš©ì ë¶„ì„ ê²°ê³¼ (Stage 1ì—ì„œ ìƒì„±)
            reference: ë ˆí¼ëŸ°ìŠ¤ ë°°ìš° ë¶„ì„ ê²°ê³¼
            dtw_result: DTW ë™ê¸°í™” ê²°ê³¼ (Stage 2ì—ì„œ ìƒì„±)
            
        Returns:
            ScoringResult: ì¢…í•© í‰ê°€ ê²°ê³¼
        """
        # ì›Œí•‘ ê²½ë¡œì—ì„œ ì •ë ¬ëœ í”„ë ˆì„ ìŒ ì¶”ì¶œ
        aligned_pairs = dtw_result.warping_path

        if not aligned_pairs:
            return self._empty_result(dtw_result)

        # 1. ì˜¤ë””ì˜¤ ì ìˆ˜ ê³„ì‚°
        pitch_detail = self._score_pitch(
            user_analysis, reference, aligned_pairs
        )
        energy_detail = self._score_energy(
            user_analysis, reference, aligned_pairs
        )

        # 2. ë¹„ë””ì˜¤(í‘œì •) ì ìˆ˜ ê³„ì‚°
        expression_detail = self._score_expression(
            user_analysis, reference, aligned_pairs
        )

        # 3. ì¢…í•© ì ìˆ˜ ê³„ì‚°
        total_score = (
            pitch_detail.score * self.weight_pitch +
            energy_detail.score * self.weight_energy +
            expression_detail.score * self.weight_expression
        )

        # 4. ì¢…í•© í”¼ë“œë°± ìƒì„±
        overall_feedback = self._generate_overall_feedback(
            total_score, pitch_detail, energy_detail, expression_detail
        )

        return ScoringResult(
            total_score=round(total_score, 1),
            audio_pitch_score=pitch_detail,
            audio_energy_score=energy_detail,
            video_expression_score=expression_detail,
            dtw_result=dtw_result,
            overall_feedback=overall_feedback,
        )

    def score_with_details(
        self,
        user_analysis: AnalysisResult,
        reference: AnalysisResult,
        dtw_result: DTWResult,
    ) -> tuple[ScoringResult, list[FrameScore]]:
        """
        ìƒì„¸ í”„ë ˆì„ë³„ ì ìˆ˜ì™€ í•¨ê»˜ í‰ê°€.
        
        Returns:
            (ScoringResult, frame_scores)
        """
        result = self.score(user_analysis, reference, dtw_result)
        frame_scores = self._calculate_frame_scores(
            user_analysis, reference, dtw_result.warping_path
        )
        return result, frame_scores

    # =========================================================================
    # ì˜¤ë””ì˜¤ ìŠ¤ì½”ì–´ë§
    # =========================================================================

    def _score_pitch(
        self,
        user: AnalysisResult,
        ref: AnalysisResult,
        aligned_pairs: list[tuple[int, int]],
    ) -> ScoreDetail:
        """
        í”¼ì¹˜(ì–µì–‘) íŒ¨í„´ ìœ ì‚¬ë„ í‰ê°€.
        
        ì ˆëŒ€ í”¼ì¹˜ê°€ ì•„ë‹Œ ìƒëŒ€ì  í”¼ì¹˜ ë³€í™” íŒ¨í„´ì„ ë¹„êµí•©ë‹ˆë‹¤.
        """
        user_pitches = []
        ref_pitches = []

        for user_idx, ref_idx in aligned_pairs:
            user_frame = user.frames[user_idx] if user_idx < len(user.frames) else None
            ref_frame = ref.frames[ref_idx] if ref_idx < len(ref.frames) else None

            if user_frame and user_frame.audio and ref_frame and ref_frame.audio:
                # ìœ ì„±ìŒ êµ¬ê°„ë§Œ ë¹„êµ (ë¬´ìŒ/ë¬´ì„±ìŒ ì œì™¸)
                if user_frame.audio.is_voiced and ref_frame.audio.is_voiced:
                    user_pitches.append(user_frame.audio.pitch)
                    ref_pitches.append(ref_frame.audio.pitch)

        if len(user_pitches) < 5:
            return ScoreDetail(
                score=50.0,
                weight=self.weight_pitch,
                feedback="ìŒì„± ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì •í™•í•œ í‰ê°€ê°€ ì–´ë µìŠµë‹ˆë‹¤.",
            )

        # í”¼ì¹˜ë¥¼ ìƒëŒ€ì  ë³€í™”ìœ¨ë¡œ ë³€í™˜ (ë¸íƒ€ í”¼ì¹˜)
        user_delta = self._compute_delta(np.array(user_pitches))
        ref_delta = self._compute_delta(np.array(ref_pitches))

        # Z-score ì •ê·œí™” í›„ ë¹„êµ
        user_norm = self._zscore_normalize(user_delta)
        ref_norm = self._zscore_normalize(ref_delta)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = self._cosine_similarity(user_norm, ref_norm)
        
        # 0-100 ì ìˆ˜ë¡œ ë³€í™˜
        score = max(0.0, min(100.0, similarity * 100))

        # í”¼ë“œë°± ìƒì„±
        feedback = self._generate_pitch_feedback(score, user_pitches, ref_pitches)

        return ScoreDetail(
            score=round(score, 1),
            weight=self.weight_pitch,
            feedback=feedback,
        )

    def _score_energy(
        self,
        user: AnalysisResult,
        ref: AnalysisResult,
        aligned_pairs: list[tuple[int, int]],
    ) -> ScoreDetail:
        """
        ì—ë„ˆì§€(ë³¼ë¥¨) íŒ¨í„´ ìœ ì‚¬ë„ í‰ê°€.
        
        ê°•ì„¸ì™€ ë³¼ë¥¨ ë³€í™” íŒ¨í„´ì„ ë¹„êµí•©ë‹ˆë‹¤.
        """
        user_energies = []
        ref_energies = []

        for user_idx, ref_idx in aligned_pairs:
            user_frame = user.frames[user_idx] if user_idx < len(user.frames) else None
            ref_frame = ref.frames[ref_idx] if ref_idx < len(ref.frames) else None

            if user_frame and user_frame.audio and ref_frame and ref_frame.audio:
                user_energies.append(user_frame.audio.energy)
                ref_energies.append(ref_frame.audio.energy)

        if len(user_energies) < 5:
            return ScoreDetail(
                score=50.0,
                weight=self.weight_energy,
                feedback="ìŒì„± ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì •í™•í•œ í‰ê°€ê°€ ì–´ë µìŠµë‹ˆë‹¤.",
            )

        # Min-Max ì •ê·œí™” (ë³¼ë¥¨ ì°¨ì´ ë³´ì •)
        user_norm = self._minmax_normalize(np.array(user_energies))
        ref_norm = self._minmax_normalize(np.array(ref_energies))

        # ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ ìœ ì‚¬ë„
        correlation = np.corrcoef(user_norm, ref_norm)[0, 1]
        if np.isnan(correlation):
            correlation = 0.0

        # 0-100 ì ìˆ˜ë¡œ ë³€í™˜ (ìƒê´€ê³„ìˆ˜ -1~1 â†’ 0~100)
        score = max(0.0, min(100.0, (correlation + 1) * 50))

        # í”¼ë“œë°± ìƒì„±
        feedback = self._generate_energy_feedback(score, user_energies, ref_energies)

        return ScoreDetail(
            score=round(score, 1),
            weight=self.weight_energy,
            feedback=feedback,
        )

    # =========================================================================
    # ë¹„ë””ì˜¤(í‘œì •) ìŠ¤ì½”ì–´ë§
    # =========================================================================

    def _score_expression(
        self,
        user: AnalysisResult,
        ref: AnalysisResult,
        aligned_pairs: list[tuple[int, int]],
    ) -> ScoreDetail:
        """
        í‘œì •(ë¸”ë Œë“œì‰ì…) ìœ ì‚¬ë„ í‰ê°€.
        
        ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ë¸”ë Œë“œì‰ì… ë²¡í„°ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
        """
        frame_scores = []
        valid_frames = 0
        face_detection_rate = 0

        for user_idx, ref_idx in aligned_pairs:
            user_frame = user.frames[user_idx] if user_idx < len(user.frames) else None
            ref_frame = ref.frames[ref_idx] if ref_idx < len(ref.frames) else None

            if not (user_frame and user_frame.video and 
                    ref_frame and ref_frame.video):
                continue

            # ì–¼êµ´ ê²€ì¶œ ì—¬ë¶€ ì²´í¬
            if user_frame.video.face_detected:
                face_detection_rate += 1

            if not (user_frame.video.blendshapes and 
                    ref_frame.video.blendshapes):
                continue

            valid_frames += 1

            # ë¸”ë Œë“œì‰ì… ë²¡í„° ì¶”ì¶œ
            user_bs = user_frame.video.blendshapes.to_vector()
            ref_bs = ref_frame.video.blendshapes.to_vector()

            # ê°€ì¤‘ì¹˜ ì ìš©
            weights = self._get_blendshape_weights()
            user_weighted = np.array(user_bs) * weights
            ref_weighted = np.array(ref_bs) * weights

            # í”„ë ˆì„ë³„ ìœ ì‚¬ë„ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
            similarity = self._cosine_similarity(user_weighted, ref_weighted)
            frame_scores.append(max(0.0, similarity))

        if valid_frames < 5:
            detection_pct = (face_detection_rate / len(aligned_pairs) * 100 
                           if aligned_pairs else 0)
            return ScoreDetail(
                score=50.0,
                weight=self.weight_expression,
                feedback=f"ì–¼êµ´ ì¸ì‹ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤ ({detection_pct:.0f}%). "
                        f"ì¹´ë©”ë¼ë¥¼ ì •ë©´ìœ¼ë¡œ ë°”ë¼ë´ ì£¼ì„¸ìš”.",
            )

        # í‰ê·  ì ìˆ˜
        avg_score = np.mean(frame_scores) * 100

        # í”¼ë“œë°± ìƒì„±
        feedback = self._generate_expression_feedback(
            avg_score, frame_scores, face_detection_rate / len(aligned_pairs)
        )

        return ScoreDetail(
            score=round(avg_score, 1),
            weight=self.weight_expression,
            feedback=feedback,
        )

    def _get_blendshape_weights(self) -> NDArray[np.floating]:
        """ë¸”ë Œë“œì‰ì… ê°€ì¤‘ì¹˜ ë²¡í„° ë°˜í™˜ (to_vector() ìˆœì„œì™€ ë™ì¼)."""
        keys = [
            "jawOpen",
            "mouthSmileLeft", "mouthSmileRight",
            "mouthFrownLeft", "mouthFrownRight",
            "mouthPucker", "mouthLeft", "mouthRight",
            "browInnerUp", "browDownLeft", "browDownRight",
            "browOuterUpLeft", "browOuterUpRight",
            "eyeWideLeft", "eyeWideRight",
            "eyeSquintLeft", "eyeSquintRight",
            "eyeBlinkLeft", "eyeBlinkRight",
            "cheekPuff", "noseSneerLeft", "noseSneerRight",
        ]
        weights = [self.BLENDSHAPE_WEIGHTS.get(k, 1.0) for k in keys]
        # ì •ê·œí™”
        weights = np.array(weights)
        return weights / np.sum(weights) * len(weights)

    # =========================================================================
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
    # =========================================================================

    @staticmethod
    def _compute_delta(arr: NDArray[np.floating]) -> NDArray[np.floating]:
        """ì‹œê³„ì—´ì˜ ë³€í™”ëŸ‰(ë¸íƒ€) ê³„ì‚°."""
        if len(arr) < 2:
            return arr
        return np.diff(arr)

    @staticmethod
    def _zscore_normalize(arr: NDArray[np.floating]) -> NDArray[np.floating]:
        """Z-score ì •ê·œí™”."""
        if len(arr) == 0:
            return arr
        mean = np.mean(arr)
        std = np.std(arr)
        if std < 1e-8:
            return arr - mean
        return (arr - mean) / std

    @staticmethod
    def _minmax_normalize(arr: NDArray[np.floating]) -> NDArray[np.floating]:
        """Min-Max ì •ê·œí™” (0-1 ë²”ìœ„)."""
        if len(arr) == 0:
            return arr
        min_val = np.min(arr)
        max_val = np.max(arr)
        range_val = max_val - min_val
        if range_val < 1e-8:
            return np.zeros_like(arr)
        return (arr - min_val) / range_val

    @staticmethod
    def _cosine_similarity(a: NDArray[np.floating], b: NDArray[np.floating]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (0-1 ë²”ìœ„)."""
        if len(a) == 0 or len(b) == 0:
            return 0.0
        
        # ê¸¸ì´ ë§ì¶”ê¸°
        min_len = min(len(a), len(b))
        a, b = a[:min_len], b[:min_len]
        
        norm_a = np.linalg.norm(a)
        norm_b = np.linalg.norm(b)
        
        if norm_a < 1e-8 or norm_b < 1e-8:
            return 0.0
            
        similarity = np.dot(a, b) / (norm_a * norm_b)
        # -1~1 â†’ 0~1 ë³€í™˜
        return (similarity + 1) / 2

    @staticmethod
    def _get_grade(score: float) -> ScoreGrade:
        """ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜."""
        if score >= 90:
            return ScoreGrade.S
        elif score >= 80:
            return ScoreGrade.A
        elif score >= 70:
            return ScoreGrade.B
        elif score >= 60:
            return ScoreGrade.C
        elif score >= 50:
            return ScoreGrade.D
        else:
            return ScoreGrade.F

    # =========================================================================
    # í”¼ë“œë°± ìƒì„±
    # =========================================================================

    def _generate_pitch_feedback(
        self,
        score: float,
        user_pitches: list[float],
        ref_pitches: list[float],
    ) -> str:
        """í”¼ì¹˜ ì ìˆ˜ì— ëŒ€í•œ í”¼ë“œë°± ìƒì„±."""
        grade = self._get_grade(score)
        
        # í”¼ì¹˜ ë²”ìœ„ ë¶„ì„
        user_range = max(user_pitches) - min(user_pitches) if user_pitches else 0
        ref_range = max(ref_pitches) - min(ref_pitches) if ref_pitches else 0
        
        if grade in (ScoreGrade.S, ScoreGrade.A):
            return "ì–µì–‘ íŒ¨í„´ì´ ë ˆí¼ëŸ°ìŠ¤ì™€ ë§¤ìš° ìœ ì‚¬í•©ë‹ˆë‹¤. í›Œë¥­í•´ìš”!"
        elif grade == ScoreGrade.B:
            return "ì–µì–‘ì´ ëŒ€ì²´ë¡œ ì˜ ë§ì§€ë§Œ, ì¼ë¶€ êµ¬ê°„ì—ì„œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤."
        elif grade == ScoreGrade.C:
            if user_range < ref_range * 0.7:
                return "ì–µì–‘ ë³€í™”ê°€ ë‹¤ì†Œ í‰íƒ„í•©ë‹ˆë‹¤. ê°ì •ì„ ë” ì‹¤ì–´ ë§í•´ë³´ì„¸ìš”."
            elif user_range > ref_range * 1.3:
                return "ì–µì–‘ ë³€í™”ê°€ ê³¼í•©ë‹ˆë‹¤. ì¡°ê¸ˆ ë” ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´ë³´ì„¸ìš”."
            return "ì–µì–‘ íŒ¨í„´ì„ ë ˆí¼ëŸ°ìŠ¤ì— ë§ì¶° ì—°ìŠµí•´ë³´ì„¸ìš”."
        else:
            return "ì–µì–‘ì´ ë ˆí¼ëŸ°ìŠ¤ì™€ ë§ì´ ë‹¤ë¦…ë‹ˆë‹¤. ëŒ€ì‚¬ì˜ ê°ì •ì„ ì„ ë‹¤ì‹œ í™•ì¸í•´ë³´ì„¸ìš”."

    def _generate_energy_feedback(
        self,
        score: float,
        user_energies: list[float],
        ref_energies: list[float],
    ) -> str:
        """ì—ë„ˆì§€ ì ìˆ˜ì— ëŒ€í•œ í”¼ë“œë°± ìƒì„±."""
        grade = self._get_grade(score)
        
        user_avg = np.mean(user_energies) if user_energies else 0
        ref_avg = np.mean(ref_energies) if ref_energies else 0
        
        if grade in (ScoreGrade.S, ScoreGrade.A):
            return "ë³¼ë¥¨ê³¼ ê°•ì„¸ê°€ ë ˆí¼ëŸ°ìŠ¤ì™€ ì˜ ë§ìŠµë‹ˆë‹¤!"
        elif grade == ScoreGrade.B:
            return "ë³¼ë¥¨ íŒ¨í„´ì´ ëŒ€ì²´ë¡œ ì¢‹ì§€ë§Œ, ê°•ì„¸ ìœ„ì¹˜ë¥¼ ì¡°ê¸ˆ ë” ë§ì¶°ë³´ì„¸ìš”."
        elif grade == ScoreGrade.C:
            if user_avg < ref_avg * 0.7:
                return "ì „ì²´ì ìœ¼ë¡œ ì†Œë¦¬ê°€ ì‘ìŠµë‹ˆë‹¤. ë” í¬ê²Œ ë§í•´ë³´ì„¸ìš”."
            elif user_avg > ref_avg * 1.3:
                return "ì „ì²´ì ìœ¼ë¡œ ì†Œë¦¬ê°€ í½ë‹ˆë‹¤. ë³¼ë¥¨ì„ ì¡°ì ˆí•´ë³´ì„¸ìš”."
            return "ê°•ì„¸ì™€ ë³¼ë¥¨ ë³€í™”ë¥¼ ë ˆí¼ëŸ°ìŠ¤ì— ë§ì¶° ì—°ìŠµí•´ë³´ì„¸ìš”."
        else:
            return "ë³¼ë¥¨ íŒ¨í„´ì´ ë§ì´ ë‹¤ë¦…ë‹ˆë‹¤. ëŒ€ì‚¬ì˜ ê°•ì•½ì„ ë‹¤ì‹œ í™•ì¸í•´ë³´ì„¸ìš”."

    def _generate_expression_feedback(
        self,
        score: float,
        frame_scores: list[float],
        face_detection_rate: float,
    ) -> str:
        """í‘œì • ì ìˆ˜ì— ëŒ€í•œ í”¼ë“œë°± ìƒì„±."""
        grade = self._get_grade(score)
        
        if face_detection_rate < 0.8:
            return f"ì–¼êµ´ ì¸ì‹ë¥ ({face_detection_rate:.0%})ì´ ë‚®ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ë¥¼ ì •ë©´ìœ¼ë¡œ ë°”ë¼ë´ì£¼ì„¸ìš”."
        
        if grade in (ScoreGrade.S, ScoreGrade.A):
            return "í‘œì • ì—°ê¸°ê°€ ë ˆí¼ëŸ°ìŠ¤ì™€ ë§¤ìš° ìœ ì‚¬í•©ë‹ˆë‹¤. í›Œë¥­í•´ìš”!"
        elif grade == ScoreGrade.B:
            return "í‘œì •ì´ ëŒ€ì²´ë¡œ ì˜ ë§ì§€ë§Œ, ì¼ë¶€ í‘œì •ì„ ë” ê³¼ê°í•˜ê²Œ í‘œí˜„í•´ë³´ì„¸ìš”."
        elif grade == ScoreGrade.C:
            # ë³€í™”ëŸ‰ ë¶„ì„
            score_std = np.std(frame_scores) if frame_scores else 0
            if score_std < 0.1:
                return "í‘œì • ë³€í™”ê°€ ì ìŠµë‹ˆë‹¤. ê°ì •ì— ë”°ë¼ ë” ë‹¤ì–‘í•œ í‘œì •ì„ ì§€ì–´ë³´ì„¸ìš”."
            return "í‘œì •ì„ ë ˆí¼ëŸ°ìŠ¤ ë°°ìš°ì— ë§ì¶° ì—°ìŠµí•´ë³´ì„¸ìš”."
        else:
            return "í‘œì •ì´ ë ˆí¼ëŸ°ìŠ¤ì™€ ë§ì´ ë‹¤ë¦…ë‹ˆë‹¤. ë°°ìš°ì˜ í‘œì •ì„ ìì„¸íˆ ê´€ì°°í•´ë³´ì„¸ìš”."

    def _generate_overall_feedback(
        self,
        total_score: float,
        pitch: ScoreDetail,
        energy: ScoreDetail,
        expression: ScoreDetail,
    ) -> str:
        """ì¢…í•© í”¼ë“œë°± ìƒì„±."""
        grade = self._get_grade(total_score)
        
        # ê°€ì¥ ë‚®ì€ ì ìˆ˜ í•­ëª© ì°¾ê¸°
        scores = {
            "ì–µì–‘": pitch.score,
            "ë³¼ë¥¨": energy.score,
            "í‘œì •": expression.score,
        }
        weakest = min(scores, key=scores.get)
        strongest = max(scores, key=scores.get)

        if grade == ScoreGrade.S:
            return f"ğŸ­ ì™„ë²½í•œ ì—°ê¸°ì…ë‹ˆë‹¤! ëª¨ë“  í•­ëª©ì—ì„œ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë³´ì—¬ì£¼ì…¨ì–´ìš”."
        elif grade == ScoreGrade.A:
            return f"ğŸ­ í›Œë¥­í•œ ì—°ê¸°ì…ë‹ˆë‹¤! {strongest}ì´(ê°€) íŠ¹íˆ ì¢‹ì•˜ì–´ìš”."
        elif grade == ScoreGrade.B:
            return f"ğŸ­ ì¢‹ì€ ì—°ê¸°ì…ë‹ˆë‹¤! {weakest}ì„(ë¥¼) ì¡°ê¸ˆ ë” ì—°ìŠµí•˜ë©´ ë” ì¢‹ì•„ì§ˆ ê±°ì˜ˆìš”."
        elif grade == ScoreGrade.C:
            return f"ğŸ­ ê´œì°®ì€ ì‹œë„ì…ë‹ˆë‹¤! {weakest}ì— ì§‘ì¤‘í•´ì„œ ì—°ìŠµí•´ë³´ì„¸ìš”."
        elif grade == ScoreGrade.D:
            return f"ğŸ­ ì¡°ê¸ˆ ë” ë…¸ë ¥ì´ í•„ìš”í•´ìš”. ë ˆí¼ëŸ°ìŠ¤ ì˜ìƒì„ ë‹¤ì‹œ ë³´ë©´ì„œ {weakest}ì„(ë¥¼) ì—°ìŠµí•´ë³´ì„¸ìš”."
        else:
            return f"ğŸ­ ë ˆí¼ëŸ°ìŠ¤ ì˜ìƒì„ ì²œì²œíˆ ë¶„ì„í•˜ê³ , í•˜ë‚˜ì”© ë”°ë¼í•´ë³´ì„¸ìš”. ì—°ìŠµí•˜ë©´ ë°˜ë“œì‹œ ëŠ˜ì–´ìš”!"

    def _empty_result(self, dtw_result: DTWResult) -> ScoringResult:
        """ë¹ˆ ê²°ê³¼ ë°˜í™˜."""
        return ScoringResult(
            total_score=0.0,
            audio_pitch_score=ScoreDetail(
                score=0.0, weight=self.weight_pitch, feedback="ë°ì´í„° ë¶€ì¡±"
            ),
            audio_energy_score=ScoreDetail(
                score=0.0, weight=self.weight_energy, feedback="ë°ì´í„° ë¶€ì¡±"
            ),
            video_expression_score=ScoreDetail(
                score=0.0, weight=self.weight_expression, feedback="ë°ì´í„° ë¶€ì¡±"
            ),
            dtw_result=dtw_result,
            overall_feedback="ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.",
        )

    def _calculate_frame_scores(
        self,
        user: AnalysisResult,
        ref: AnalysisResult,
        aligned_pairs: list[tuple[int, int]],
    ) -> list[FrameScore]:
        """í”„ë ˆì„ë³„ ìƒì„¸ ì ìˆ˜ ê³„ì‚°."""
        frame_scores = []
        user_fps = user.fps

        for user_idx, ref_idx in aligned_pairs:
            user_frame = user.frames[user_idx] if user_idx < len(user.frames) else None
            ref_frame = ref.frames[ref_idx] if ref_idx < len(ref.frames) else None

            fs = FrameScore(
                user_frame_idx=user_idx,
                actor_frame_idx=ref_idx,
                timestamp_ms=int(user_idx * 1000 / user_fps),
            )

            # í”¼ì¹˜/ì—ë„ˆì§€ ì ìˆ˜
            if user_frame and user_frame.audio and ref_frame and ref_frame.audio:
                if user_frame.audio.is_voiced and ref_frame.audio.is_voiced:
                    # í”¼ì¹˜ ìœ ì‚¬ë„ (ë‹¨ìˆœ ë¹„ìœ¨)
                    if ref_frame.audio.pitch > 0:
                        pitch_ratio = user_frame.audio.pitch / ref_frame.audio.pitch
                        fs.pitch_score = max(0, 100 - abs(1 - pitch_ratio) * 100)
                    
                    # ì—ë„ˆì§€ ìœ ì‚¬ë„
                    if ref_frame.audio.energy > 0:
                        energy_ratio = user_frame.audio.energy / ref_frame.audio.energy
                        fs.energy_score = max(0, 100 - abs(1 - energy_ratio) * 50)

            # í‘œì • ì ìˆ˜
            if (user_frame and user_frame.video and user_frame.video.blendshapes and
                ref_frame and ref_frame.video and ref_frame.video.blendshapes):
                user_bs = np.array(user_frame.video.blendshapes.to_vector())
                ref_bs = np.array(ref_frame.video.blendshapes.to_vector())
                similarity = self._cosine_similarity(user_bs, ref_bs)
                fs.expression_score = similarity * 100

            # ì¢…í•© ì ìˆ˜
            fs.combined_score = (
                fs.pitch_score * self.weight_pitch +
                fs.energy_score * self.weight_energy +
                fs.expression_score * self.weight_expression
            )

            frame_scores.append(fs)

        return frame_scores


# =============================================================================
# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (Lazy Loading)
# =============================================================================

_scoring_service: Optional[ScoringService] = None


def get_scoring_service() -> ScoringService:
    """ScoringService ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜."""
    global _scoring_service
    if _scoring_service is None:
        _scoring_service = ScoringService()
    return _scoring_service


# =============================================================================
# CLI í…ŒìŠ¤íŠ¸ìš©
# =============================================================================

if __name__ == "__main__":
    import sys

    if len(sys.argv) < 3:
        print("Usage: python scoring_service.py <user_analysis.msgpack> <reference.msgpack>")
        print("\nNote: DTW will be computed automatically between the two analyses.")
        sys.exit(1)

    user_path = sys.argv[1]
    ref_path = sys.argv[2]

    # ë°ì´í„° ë¡œë“œ
    print(f"ğŸ“‚ ì‚¬ìš©ì ë¶„ì„ ë¡œë“œ: {user_path}")
    user_analysis = AnalysisResult.load(user_path)
    
    print(f"ğŸ“‚ ë ˆí¼ëŸ°ìŠ¤ ë¡œë“œ: {ref_path}")
    reference = AnalysisResult.load(ref_path)

    # DTW ë™ê¸°í™”
    from app.services.dtw_service import get_dtw_service
    
    print("\nğŸ”— DTW ë™ê¸°í™” ì¤‘...")
    dtw_service = get_dtw_service()
    
    # ì‚¬ìš©ì ë¶„ì„ì—ì„œ ì˜¤ë””ì˜¤ MFCC ì¶”ì¶œ
    user_mfcc = np.array(user_analysis.get_mfcc_matrix())
    dtw_result = dtw_service.synchronize(
        user_audio=user_mfcc,  # numpy array ì§ì ‘ ì „ë‹¬
        reference=reference,
        user_id="test_user",
    )

    # ìŠ¤ì½”ì–´ë§
    print("\nğŸ“Š ìŠ¤ì½”ì–´ë§ ì¤‘...")
    scoring_service = get_scoring_service()
    result = scoring_service.score(user_analysis, reference, dtw_result)

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ­ ì—°ê¸° í‰ê°€ ê²°ê³¼")
    print("=" * 60)
    
    grade = ScoringService._get_grade(result.total_score)
    print(f"\n  ğŸ“Š ì¢…í•© ì ìˆ˜: {result.total_score:.1f}/100 (ë“±ê¸‰: {grade.value})")
    
    print(f"\n  ğŸ¤ ì–µì–‘ (í”¼ì¹˜): {result.audio_pitch_score.score:.1f}/100")
    print(f"     â†’ {result.audio_pitch_score.feedback}")
    
    print(f"\n  ğŸ”Š ë³¼ë¥¨ (ì—ë„ˆì§€): {result.audio_energy_score.score:.1f}/100")
    print(f"     â†’ {result.audio_energy_score.feedback}")
    
    print(f"\n  ğŸ˜€ í‘œì •: {result.video_expression_score.score:.1f}/100")
    print(f"     â†’ {result.video_expression_score.feedback}")
    
    print(f"\n  ğŸ’¬ ì¢…í•© í”¼ë“œë°±:")
    print(f"     {result.overall_feedback}")
    print()
