import cv2
import mediapipe as mp
from mediapipe.python.solutions import face_mesh as mp_face_mesh
import numpy as np
from scipy.spatial import distance

class VideoService:
    def __init__(self):
        print("ğŸ¬ VideoService: MediaPipe ë¡œë”© ì¤‘...")
        self.mp_face_mesh = mp.solutions.face_mesh
        # ì •ë°€ë„ë¥¼ ìœ„í•´ refine_landmarks=True ì‚¬ìš© (ì…ìˆ /ëˆˆ ì£¼ë³€ ì„¸ë°€í•¨)
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        print("ğŸ¬ VideoService: ë¡œë”© ì™„ë£Œ!")

    def _calculate_blendshapes(self, landmarks):
        """
        MediaPipe 478ê°œ ëœë“œë§ˆí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•µì‹¬ í‘œì •(Blendshapes) ìˆ˜ì¹˜ë¥¼ ê³„ì‚°
        (ì‹¤ì œ ì•„ì´í° ARKitì˜ Blendshapeì™€ ìœ ì‚¬í•œ ë¡œì§ êµ¬í˜„)
        """
        def get_dist(idx1, idx2):
            # ë‘ ëœë“œë§ˆí¬ ì‚¬ì´ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
            p1 = np.array([landmarks[idx1].x, landmarks[idx1].y])
            p2 = np.array([landmarks[idx2].x, landmarks[idx2].y])
            return np.linalg.norm(p1 - p2)

        # ì–¼êµ´ í¬ê¸° ê¸°ì¤€ì  (ì–‘ìª½ ê´€ìë†€ì´ ê±°ë¦¬) - ì •ê·œí™”ìš©
        face_width = get_dist(234, 454) 
        face_height = get_dist(10, 152)
        if face_width == 0 or face_height == 0: return None

        # --- í•µì‹¬ ì—°ê¸° í¬ì¸íŠ¸ (Action Units) ê³„ì‚° ---
        # ê°’ì€ 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”í•˜ë˜, ì‚¬ëŒë§ˆë‹¤ ë‹¤ë¥´ë¯€ë¡œ ìƒëŒ€ì  ë³€í™”ëŸ‰ì´ ì¤‘ìš”í•¨
        shapes = {
            "jawOpen": get_dist(13, 14) / face_height,       # ì… ë²Œë¦¼
            "mouthSmile": get_dist(61, 291) / face_width,   # ì…ê¼¬ë¦¬ ì¢Œìš° ê¸¸ì´ 
            "browInnerUp": (get_dist(107, 9) + get_dist(9,336)) / (2 * face_width),   # ëˆˆì¹ ì¹˜ì¼œëœ¸ (ë†€ëŒ)
            "eyeWide": (get_dist(159, 145) + get_dist(386, 374)) / (2 * face_width), # ëˆˆ í¬ê²Œ ëœ¸
            "mouthFrown": (((landmarks[61].y + landmarks[291].y) / 2) - landmarks[0].y) / face_height,  # ì…ê¼¬ë¦¬ ë†’ì´ì´
            "pupil": (get_dist(468, 133) / get_dist(133, 33)),  # ëˆˆë™ì ìœ„ì¹˜
            "philtrum" : (get_dist(0,2)) / face_height # ì¸ì¤‘
        }
        return shapes

    def process_video_shapes(self, video_path: str):
        """
        ì˜ìƒ ì „ì²´ë¥¼ í”„ë ˆì„ ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ì—¬ ì‹œê³„ì—´ Blendshape ë°ì´í„°ë¥¼ ì¶”ì¶œ
        """
        cap = cv2.VideoCapture(video_path)
        shape_sequence = []

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break

            # BGR -> RGB ë³€í™˜
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.face_mesh.process(rgb_frame)

            if results.multi_face_landmarks:
                landmarks = results.multi_face_landmarks[0].landmark
                shapes = self._calculate_blendshapes(landmarks)
                if shapes:
                    shape_sequence.append(shapes)
        
        cap.release()
        return shape_sequence

    def calculate_sync_rate(self, user_shapes, target_shapes):
        """
        ë‘ ì˜ìƒì˜ Blendshape ì‹œí€€ìŠ¤ë¥¼ ë¹„êµí•˜ì—¬ í•­ëª©ë³„ ì‹±í¬ë¡œìœ¨(%) ê³„ì‚°
        Returns:
            dict: í•­ëª©ë³„ ì ìˆ˜ì™€ ì´ì ì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        keys = ["jawOpen", "mouthSmile", "browInnerUp", "eyeWide", "mouthFrown", "pupil", "philtrum"]
        
        # í•­ëª©ë³„ í•œê¸€ ì´ë¦„ ë§¤í•‘
        key_names = {
            "jawOpen": "ì… ë²Œë¦¼",
            "mouthSmile": "ì…ê¼¬ë¦¬ (ë¯¸ì†Œ)",
            "browInnerUp": "ëˆˆì¹ ì¹˜ì¼œëœ¸",
            "eyeWide": "ëˆˆ í¬ê²Œ ëœ¸",
            "mouthFrown": "ì…ê¼¬ë¦¬ ë‚´ë¦¼",
            "pupil": "ëˆˆë™ì ìœ„ì¹˜",
            "philtrum": "ì¸ì¤‘"
        }
        
        empty_result = {
            "total": 0.0,
            "details": {key: {"score": 0.0, "name": key_names[key]} for key in keys}
        }
        
        if not user_shapes or not target_shapes:
            return empty_result

        # 1. í”„ë ˆì„ ìˆ˜ ë§ì¶”ê¸° (ê°„ë‹¨íˆ ìµœì†Œ ê¸¸ì´ë¡œ ë§ì¶¤, ê³ ë„í™” ì‹œ DTW ì•Œê³ ë¦¬ì¦˜ ê¶Œì¥)
        min_len = min(len(user_shapes), len(target_shapes))
        if min_len == 0: 
            return empty_result
        
        user_seq = user_shapes[:min_len]
        target_seq = target_shapes[:min_len]

        # í•­ëª©ë³„ ì ìˆ˜ë¥¼ ëˆ„ì í•  ë”•ì…”ë„ˆë¦¬
        key_scores = {key: [] for key in keys}

        for i in range(min_len):
            for key in keys:
                u_val = user_seq[i][key]
                t_val = target_seq[i][key]
                
                # ì°¨ì´ê°€ ì‘ì„ìˆ˜ë¡ ì ìˆ˜ê°€ ë†’ìŒ (ê±°ë¦¬ ê¸°ë°˜)
                diff = abs(u_val - t_val)
                # 0.1 ì°¨ì´ë©´ 0ì , 0 ì°¨ì´ë©´ 100ì ì´ ë˜ë„ë¡ ìŠ¤ì¼€ì¼ë§
                similarity = max(0, 1 - (diff * 10)) 
                key_scores[key].append(similarity)

        # í•­ëª©ë³„ í‰ê·  ì ìˆ˜ ê³„ì‚°
        details = {}
        total_scores = []
        for key in keys:
            avg_score = (sum(key_scores[key]) / len(key_scores[key])) * 100
            rounded_score = round(avg_score, 2)
            details[key] = {
                "score": rounded_score,
                "name": key_names[key]
            }
            total_scores.append(rounded_score)

        # ì´ì  ê³„ì‚° (í•­ëª©ë³„ ì ìˆ˜ì˜ í‰ê· )
        total = round(sum(total_scores) / len(total_scores), 2)

        return {
            "total": total,
            "details": details
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ëŠ” lazy loadingìœ¼ë¡œ ë³€ê²½
video_service = None

def get_video_service():
    global video_service
    if video_service is None:
        video_service = VideoService()
    return video_service
